# -*- coding: utf-8 -*-
"""project2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f_UDU84bibmIV7p8oxbMo_CQVQBn37L4
"""

from google.colab import drive
drive.mount('/content/drive')

import zipfile
zip_path = "/content/drive/My Drive/نسخة من Teeth DataSet.zip"
extract_path = "/content/TeethData"

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

!ls /content/TeethData

!ls "/content/TeethData/Teeth_Dataset/Testing"
!ls "/content/TeethData/Teeth_Dataset/Training"
!ls "/content/TeethData/Teeth_Dataset/Validation"

# File system and OS operations
import os
import random

# Image processing libraries
!pip install opencv-python
import cv2 as cv
import numpy as np

# Data analysis and visualization
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Model evaluation metrics and data splitting
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.model_selection import train_test_split

# Deep learning libraries: building and training models
!pip install tensorflow

import tensorflow as tf
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint

# Transfer learning with pre-trained ResNet50
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.layers import GlobalAveragePooling2D

# Show random images from class folders
def show_random_images(number_of_images, folders):
    plt.figure(figsize=(15, 10))
    for i in range(number_of_images):
        folder = random.choice(folders)
        allFiles = os.listdir(folder)
        random_image = random.choice(allFiles)
        path_image = os.path.join(folder, random_image)
        img = cv.imread(path_image)
        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)

        # Use folder name as class title
        class_name = os.path.basename(folder)

        plt.subplot(2, 6, i + 1)
        plt.imshow(img)
        plt.title(f"{class_name} - Image {i+1}")
        plt.axis('off')
    plt.tight_layout()
    plt.show()
# المسارات للفئات داخل Training
base_path = "/content/TeethData/Teeth_Dataset/Training"
base_path="/content/TeethData/Teeth_Dataset/Validation"
base_path="/content/TeethData/Teeth_Dataset/Testing"
folders = [os.path.join(base_path, folder) for folder in os.listdir(base_path)
           if os.path.isdir(os.path.join(base_path, folder))]

# عرض 12 صورة عشوائية من الفئات
show_random_images(12, folders)

# Function to calculate pixel statistics for each class
def calculate_stats_per_class(folder_list, max_images_per_folder=100):
    stats = {}
    for folder in folder_list:
        class_name = os.path.basename(folder)
        means, stds, medians, mins, maxs = [], [], [], [], []

        count = 0
        for img_name in os.listdir(folder)[:max_images_per_folder]:
            img_path = os.path.join(folder, img_name)
            img = cv.imread(img_path)
            if img is not None:
                img = img.astype(np.float64) / 255.0
                means.append(np.mean(img))
                stds.append(np.std(img))
                medians.append(np.median(img))
                mins.append(np.min(img))
                maxs.append(np.max(img))
                count += 1

        if count > 0:
            stats[class_name] = {
                'mean': np.mean(means),
                'std': np.mean(stds),
                'median': np.mean(medians),
                'min': np.mean(mins),
                'max': np.mean(maxs),
                'count': count
            }
    return stats

# Function to plot statistics for all classes
def plot_class_stats(stats_dict):
    metrics = ['mean', 'std', 'median', 'min', 'max']
    class_names = list(stats_dict.keys())

    for metric in metrics:
        values = [stats_dict[class_name][metric] for class_name in class_names]

        plt.figure(figsize=(10, 5))
        plt.bar(class_names, values, color='pink')
        plt.title(f'{metric.capitalize()} Pixel Value per Class')
        plt.ylabel('Value')
        plt.xlabel('Class Name')
        plt.xticks(rotation=45)
        plt.grid(True, linestyle='--', alpha=0.6)
        plt.tight_layout()
        plt.show()

import os

train_path = "/content/TeethData/Teeth_Dataset/Testing"

class_folders = [
    os.path.join(train_path, folder)
    for folder in os.listdir(train_path)
    if os.path.isdir(os.path.join(train_path, folder))
]

print("2 - Calculating basic statistics for each class...")

class_stats = calculate_stats_per_class(class_folders)

for class_name, stats in class_stats.items():
    print(f"\nClass: {class_name}")
    print(f"Mean: {stats['mean']:.3f}, Std: {stats['std']:.3f}")
    print(f"Median: {stats['median']:.3f}, Range: [{stats['min']:.3f}, {stats['max']:.3f}]")
    print(f"Image Count: {stats['count']}")

plot_class_stats(class_stats)

from sklearn.model_selection import train_test_split

def shuffleData(data):
    data = list(data)
    indices = list(range(len(data)))
    random.shuffle(indices)
    return [data[i] for i in indices]

base_path = "/content/TeethData/Teeth_Dataset"

train_path = os.path.join(base_path, "Training")
val_path = os.path.join(base_path, "Validation")
test_path = os.path.join(base_path, "Testing")

# جلب مجلدات الفئات لكل مجموعة
train_class_folders = [os.path.join(train_path, c) for c in os.listdir(train_path) if os.path.isdir(os.path.join(train_path, c))]
val_class_folders = [os.path.join(val_path, c) for c in os.listdir(val_path) if os.path.isdir(os.path.join(val_path, c))]
test_class_folders = [os.path.join(test_path, c) for c in os.listdir(test_path) if os.path.isdir(os.path.join(test_path, c))]

print(f"Train classes folders: {train_class_folders}")
print(f"Validation classes folders: {val_class_folders}")
print(f"Test classes folders: {test_class_folders}")

# دالة تحميل ومعالجة الصور
def load_and_preprocess_images(folders, augment=False, img_size=(64,64)):
    X = []
    y = []

    for idx, folder in enumerate(folders):
        all_files = [f for f in os.listdir(folder) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]
        all_files = shuffleData(all_files)
        for img_name in all_files:
            img_path = os.path.join(folder, img_name)
            img = cv.imread(img_path)
            if img is not None:
                img = cv.cvtColor(img, cv.COLOR_BGR2RGB)
                resized = cv.resize(img, img_size)
                normalized = resized.astype(np.float32) / 255.0
                X.append(normalized)
                y.append(idx)

                if augment:
                    flipped = cv.flip(normalized, 1)
                    brightened = np.clip(normalized + 0.25, 0, 1)
                    X.append(flipped)
                    y.append(idx)
                    X.append(brightened)
                    y.append(idx)

    return np.array(X), np.array(y)

# تحميل البيانات
X_train, y_train = load_and_preprocess_images(train_class_folders, augment=True)
X_val, y_val = load_and_preprocess_images(val_class_folders, augment=False)
X_test, y_test = load_and_preprocess_images(test_class_folders, augment=False)

print(f"Train samples: {len(X_train)}")
print(f"Validation samples: {len(X_val)}")
print(f"Test samples: {len(X_test)}")

def show_sample_images(X, y, class_names, samples_per_class=3):
    plt.figure(figsize=(15, 8))
    unique_classes = np.unique(y)
    count = 1
    for cls in unique_classes:
        idxs = np.where(y == cls)[0][:samples_per_class]
        for i in idxs:
            plt.subplot(len(unique_classes), samples_per_class, count)
            plt.imshow(X[i])
            plt.title(class_names[cls])
            plt.axis('off')
            count +=1
    plt.tight_layout()
    plt.show()

class_names = [os.path.basename(folder) for folder in train_class_folders]

show_sample_images(X_train, y_train, class_names)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.utils import to_categorical

def create_cnn_model(input_shape=(64,64,3), num_classes=7):
    model = Sequential([
        Conv2D(32, (3,3), activation='relu', input_shape=input_shape),
        BatchNormalization(),
        MaxPooling2D(2,2),

        Conv2D(64, (3,3), activation='relu'),
        BatchNormalization(),
        MaxPooling2D(2,2),

        Conv2D(128, (3,3), activation='relu'),
        BatchNormalization(),
        MaxPooling2D(2,2),

        Flatten(),
        Dense(256, activation='relu'),
        Dropout(0.5),
        Dense(num_classes, activation='softmax')
    ])

    model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    return model

def train_cnn_model(X_train, y_train, X_val, y_val, num_classes=7):
    y_train_cat = to_categorical(y_train, num_classes)
    y_val_cat = to_categorical(y_val, num_classes)

    model = create_cnn_model(X_train.shape[1:], num_classes)
    model.summary()

    callbacks = [
        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),
        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-6, verbose=1),
        ModelCheckpoint('best_cnn_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)
    ]

    history = model.fit(
        X_train, y_train_cat,
        epochs=15,
        batch_size=32,
        validation_data=(X_val, y_val_cat),
        callbacks=callbacks,
        verbose=1
    )

    model.save('final_cnn_model.h5')
    print("Model saved as 'final_cnn_model.h5'")

    return model, history

import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import numpy as np
import pandas as pd

def plot_training_history(history):
    plt.figure(figsize=(12,5))
    plt.subplot(1,2,1)
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title('Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()

    plt.subplot(1,2,2)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()

    plt.tight_layout()
    plt.show()

def plot_confusion_matrix_and_report(y_true, y_pred, class_names):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(8,6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.title('Confusion Matrix')
    plt.show()

    report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)
    report_df = pd.DataFrame(report).iloc[:-1, :-3].T  # حذف المتوسطات
    plt.figure(figsize=(10,6))
    sns.heatmap(report_df, annot=True, cmap='Greens')
    plt.title('Classification Report')
    plt.show()

# استخدام التقييم
def evaluate_model(model, X_test, y_test, class_names):
    y_pred_probs = model.predict(X_test)
    y_pred = np.argmax(y_pred_probs, axis=1)

    plot_confusion_matrix_and_report(y_test, y_pred, class_names)

# أسماء الفئات
class_names = ['out','output','outputs','CaS', 'CoS', 'Gum', 'MC', 'OC', 'OLP', 'OT']

# عدد الفئات
num_classes = len(class_names)

# تدريب النموذج
cnn_model, history = train_cnn_model(X_train, y_train, X_val, y_val, num_classes=num_classes)

# عرض نتائج التدريب
plot_training_history(history)

# تقييم النموذج على بيانات الاختبار
evaluate_model(cnn_model, X_test, y_test, class_names)